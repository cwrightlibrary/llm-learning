{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2056f84a",
   "metadata": {},
   "source": [
    "# PyTorch Overview & Examples\n",
    "\n",
    "From section [PyTorch Overview (32.28)](https://www.youtube.com/watch?v=UU1WVnMk4E8&t=2008s) in tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245c5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979988e",
   "metadata": {},
   "source": [
    "### `torch.randint`\n",
    "\n",
    "Using `torch.randint` let's us choose the range (first two numbers), `(min, max)` as well as how many random integers in the output, `(6,)`, for the **tensor** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9b729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 45, -89, -42, -97, -15,  66])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randint = torch.randint(-100, 100, (6,))\n",
    "randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c0725",
   "metadata": {},
   "source": [
    "### `torch.tensor`\n",
    "\n",
    "This sets up a tensor object, each sublist is a new row, sets up a matrix:\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "| 0.1 | 1.2 |\n",
    "| 2.2 | 3.1 |\n",
    "| 4.9 | 5.2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f106bcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.2000],\n",
       "        [2.2000, 3.1000],\n",
       "        [4.9000, 5.2000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037388fb",
   "metadata": {},
   "source": [
    "### `torch.zeroes`\n",
    "\n",
    "This defines an empty shape for a tensor. It defines the shape, made up of floats, by $\\text{rows}\\times \\text{columns}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113d6d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef5090",
   "metadata": {},
   "source": [
    "### `torch.ones`\n",
    "\n",
    "Same as zeros, define the shape, made up of float 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5be324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3, 5)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efa49d",
   "metadata": {},
   "source": [
    "### `torch.arange`\n",
    "\n",
    "This creates a tensor object in a range, in this case `5`, which is `0`...`5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e076887e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = torch.arange(5)\n",
    "arange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a129b9c",
   "metadata": {},
   "source": [
    "### `torch.linspace`\n",
    "\n",
    "Similarly, this creates a range, in our case between `3` and `10`, calculating the difference between the numbers by the `step` size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40db270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linspace = torch.linspace(3, 10, steps=5)\n",
    "linspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6756e",
   "metadata": {},
   "source": [
    "Let's check what the constant increment is between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ffe7595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = float(linspace[1])\n",
    "n2 = float(linspace[0])\n",
    "n1 - n2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d49926",
   "metadata": {},
   "source": [
    "### `torch.logspace`\n",
    "\n",
    "This function differs in that it `start`s at $1^n$, `end`s at $1^n$, with automatically calculated `step`s defined. In our case, $1^{-10}$ to $1^{10}$ in `5` steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc9f637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logspace = torch.logspace(start=-10, end=10, steps=5)\n",
    "logspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78de06",
   "metadata": {},
   "source": [
    "### `torch.eye`\n",
    "\n",
    "This creates a matrix where the value `1.0` is assigned to every next column and row and the shape is defined by the argument, in our case `5`.\n",
    "\n",
    "| | | | | |\n",
    "|---|---|---|---|---|\n",
    "| 1.0 | | | | |\n",
    "| | 1.0 | | | |\n",
    "| | | 1.0 | | |\n",
    "| | | | 1.0 | |\n",
    "| | | | | 1.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d756cc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye = torch.eye(5)\n",
    "eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a2fc2",
   "metadata": {},
   "source": [
    "### `torch.empty_like`\n",
    "\n",
    "The main emphasis here is the datatype, in our case `dtype=torch.int64`. Instead of creating an empty of floating point values, we can define what datatype the tensor should include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a92896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_like = torch.empty_like(torch.empty(2, 3), dtype=torch.int64)\n",
    "empty_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5885cf2",
   "metadata": {},
   "source": [
    "### CPU vs GPU (m1 (`mps`)) performance in `torch`\n",
    "\n",
    "Let's compare the difference in speed between CPU and m1 on Mac, `mps`. First, let's set our device to `mps` and import some other libraries. We'll test `numpy` on the `cpu` and `torch` on the m1 `mps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b51ab321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c64149",
   "metadata": {},
   "source": [
    "Let's measure `mps` time with this calculation. Again, we're mainly concerned with the iterative process time. Let's create a 10,000x10,000 tensor object of floating point numbers pushed to the m1 and do the same thing in `numpy`.\n",
    "\n",
    "To multiply matrices in `torch`, we'll use the `@` symbol (line 8), and it'll give us a new random tensor. To multiply them in `numpy`, we use `np.multiply`. Let's compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b757b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 time:  0.02777719\n",
      "cpu time:  0.53274226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/bp828d7j3xn9rrsxwk7p7kjr0000gn/T/ipykernel_50046/1189135628.py:17: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  rand = np.multiply(np_rand1, np_rand2)\n"
     ]
    }
   ],
   "source": [
    "torch_rand1 = torch.rand(10000, 10000).to(device)\n",
    "torch_rand2 = torch.rand(10000, 10000).to(device)\n",
    "np_rand1 = torch.rand(10000, 10000)\n",
    "np_rand2 = torch.rand(10000, 10000)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = (torch_rand1 @ torch_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"m1 time: {elapsed_time: .8f}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"cpu time: {elapsed_time: .8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafdf48",
   "metadata": {},
   "source": [
    "The difference isn't very big. The m1 is definitely faster, here, but not by a ton. The example in the video was `0.89495587` and `0.08935308`, so my CPU is definitely much slower. My m1 `mps` speed doesn't even match the much faster CPU on his computer.\n",
    "\n",
    "The idea is that the CPU handles very quickly because there isn't much to do. Let's change the shape of the matrix and check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36834960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 time:  0.02763176\n",
      "cpu time:  0.09301782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/bp828d7j3xn9rrsxwk7p7kjr0000gn/T/ipykernel_50046/1315394993.py:17: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  rand = np.multiply(np_rand1, np_rand2)\n"
     ]
    }
   ],
   "source": [
    "torch_rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "np_rand1 = torch.rand(100, 100, 100, 100)\n",
    "np_rand2 = torch.rand(100, 100, 100, 100)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = (torch_rand1 @ torch_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"m1 time: {elapsed_time: .8f}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"cpu time: {elapsed_time: .8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b415445",
   "metadata": {},
   "source": [
    "It seems that running things a second time speeds it up for some reason, my first numbers were far worse than the ones above. A lot of simple tasks is what the m1 (GPU) thrives on, a single, more complex problem is where the CPU thrives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
